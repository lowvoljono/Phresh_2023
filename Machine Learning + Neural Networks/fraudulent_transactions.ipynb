{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Predicting Fraudulent Transactions Using Neural Networks\n",
    "\n",
    "Now that you’ve learned how to build a deep neural network, you’ll apply those skills to create a deep learning model that can predict financial fraud. But in this activity, rather than a regression deep learning model, you will create a classification deep learning model.\n",
    "\n",
    "## Instructions:\n",
    "\n",
    "### Load and Preprocess the Data\n",
    "\n",
    "1. Read the data from the CSV file into a Pandas DataFrame.\n",
    "\n",
    "2. Create the target set `y` by assigning the values of the “isFraud” column of the DataFrame.\n",
    "\n",
    "3. Define the features set `X` by including all of the columns of the DataFrame except for the “isFraud” column.\n",
    "\n",
    "4. Create the training and testing sets using the `train_test_split` function from scikit-learn.\n",
    "\n",
    "5. Scale the features data using the `StandardScaler` from scikit-learn.\n",
    "\n",
    "### Create and Evaluate a Deep Neural Network Model\n",
    "\n",
    "1. Create a deep neural network model with the following structure:\n",
    "\n",
    "    * 9 inputs\n",
    "    * First hidden layer with 18 neurons\n",
    "    * Second hidden layer with 8 neurons\n",
    "    * Output layer with a single output\n",
    "    * Hidden layers use the ReLU activation function, and output layer uses the sigmoid activation function\n",
    "\n",
    "2. Display the model structure using the 'summary` function.\n",
    "\n",
    "3. Compile the neural network model using the `binary_crossentropy` loss function, the `adam` optimizer, and `accuracy` as an additional metric.\n",
    "\n",
    "4. Fit the model with the training data, using 100 epochs.\n",
    "\n",
    "5. Evaluate the model using testing data and the `evaluate` method.\n",
    "\n",
    "\n",
    "## References:\n",
    "\n",
    "[Keras Sequential model](https://keras.io/api/models/sequential/)\n",
    "\n",
    "[Keras Dense module](https://keras.io/api/layers/core_layers/dense/)\n",
    "\n",
    "[Keras evaluate](https://keras.io/api/models/model_training_apis/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import pandas as pd\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.models import Sequential\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and Preprocess the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Read the data from the CSV file into a Pandas DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateMonth</th>\n",
       "      <th>dateWeekday</th>\n",
       "      <th>dateQuarter</th>\n",
       "      <th>operationType</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrig</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "      <th>isFraud</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>736.76</td>\n",
       "      <td>1120.00</td>\n",
       "      <td>383.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>256226.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>518041.64</td>\n",
       "      <td>1305828.01</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>310027.49</td>\n",
       "      <td>61594.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10089.00</td>\n",
       "      <td>1157398.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76695.35</td>\n",
       "      <td>9064440.33</td>\n",
       "      <td>9141135.68</td>\n",
       "      <td>880045.33</td>\n",
       "      <td>206147.08</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4761.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>109534.19</td>\n",
       "      <td>18292168.76</td>\n",
       "      <td>18401702.96</td>\n",
       "      <td>403737.01</td>\n",
       "      <td>294202.82</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>103920.74</td>\n",
       "      <td>5486901.65</td>\n",
       "      <td>5590822.39</td>\n",
       "      <td>1267095.24</td>\n",
       "      <td>2239899.53</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1298677.95</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>280579.46</td>\n",
       "      <td>1579257.41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>82450.63</td>\n",
       "      <td>4135263.42</td>\n",
       "      <td>4217714.05</td>\n",
       "      <td>2289239.02</td>\n",
       "      <td>2436585.65</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>78848.28</td>\n",
       "      <td>144962.00</td>\n",
       "      <td>223810.28</td>\n",
       "      <td>13861.87</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       dateMonth  dateWeekday  dateQuarter  operationType      amount  \\\n",
       "0              1            1            1              4      736.76   \n",
       "1              1            1            1              2   256226.20   \n",
       "2              1            1            1              5   310027.49   \n",
       "3              1            1            1              1    76695.35   \n",
       "4              1            1            1              4     4761.57   \n",
       "...          ...          ...          ...            ...         ...   \n",
       "99995         12            1            4              1   109534.19   \n",
       "99996         12            1            4              1   103920.74   \n",
       "99997         12            1            4              5  1298677.95   \n",
       "99998         12            1            4              1    82450.63   \n",
       "99999         12            1            4              1    78848.28   \n",
       "\n",
       "       oldbalanceOrig  newbalanceOrig  oldbalanceDest  newbalanceDest  isFraud  \n",
       "0             1120.00          383.24            0.00            0.00        0  \n",
       "1                0.00            0.00       518041.64      1305828.01        0  \n",
       "2            61594.00            0.00        10089.00      1157398.83        0  \n",
       "3          9064440.33      9141135.68       880045.33       206147.08        0  \n",
       "4                0.00            0.00            0.00            0.00        0  \n",
       "...               ...             ...             ...             ...      ...  \n",
       "99995     18292168.76     18401702.96       403737.01       294202.82        0  \n",
       "99996      5486901.65      5590822.39      1267095.24      2239899.53        0  \n",
       "99997            0.00            0.00       280579.46      1579257.41        0  \n",
       "99998      4135263.42      4217714.05      2289239.02      2436585.65        0  \n",
       "99999       144962.00       223810.28        13861.87            0.00        0  \n",
       "\n",
       "[100000 rows x 10 columns]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the credit_card_transactions.csv file from the Resources folder into a Pandas DataFrame\n",
    "cc_transactions_df = pd.read_csv('credit_card_transactions.csv')\n",
    "cc_transactions_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Create the target set `y` by assigning the values of the “isFraud” column of the DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.series.Series"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the target set by selecting the isFraud column\n",
    "y = cc_transactions_df['isFraud']\n",
    "type(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Define the features set `X` by including all of the columns of the DataFrame except for the “isFraud” column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dateMonth</th>\n",
       "      <th>dateWeekday</th>\n",
       "      <th>dateQuarter</th>\n",
       "      <th>operationType</th>\n",
       "      <th>amount</th>\n",
       "      <th>oldbalanceOrig</th>\n",
       "      <th>newbalanceOrig</th>\n",
       "      <th>oldbalanceDest</th>\n",
       "      <th>newbalanceDest</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>736.76</td>\n",
       "      <td>1120.00</td>\n",
       "      <td>383.24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>256226.20</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>518041.64</td>\n",
       "      <td>1305828.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>310027.49</td>\n",
       "      <td>61594.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>10089.00</td>\n",
       "      <td>1157398.83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>76695.35</td>\n",
       "      <td>9064440.33</td>\n",
       "      <td>9141135.68</td>\n",
       "      <td>880045.33</td>\n",
       "      <td>206147.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4761.57</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   dateMonth  dateWeekday  dateQuarter  operationType     amount  \\\n",
       "0          1            1            1              4     736.76   \n",
       "1          1            1            1              2  256226.20   \n",
       "2          1            1            1              5  310027.49   \n",
       "3          1            1            1              1   76695.35   \n",
       "4          1            1            1              4    4761.57   \n",
       "\n",
       "   oldbalanceOrig  newbalanceOrig  oldbalanceDest  newbalanceDest  \n",
       "0         1120.00          383.24            0.00            0.00  \n",
       "1            0.00            0.00       518041.64      1305828.01  \n",
       "2        61594.00            0.00        10089.00      1157398.83  \n",
       "3      9064440.33      9141135.68       880045.33       206147.08  \n",
       "4            0.00            0.00            0.00            0.00  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = cc_transactions_df.drop(columns=['isFraud'])\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Create the training and testing sets using the `train_test_split` function from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create training and testing datasets using train_teat_split\n",
    "# Assign the function a random_state equal to 1\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5:  Scale the features data using the `StandardScaler` from scikit-learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StandardScaler instance\n",
    "X_scaler = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler()"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit the scaler to the features training dataset\n",
    "X_scaler.fit(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale both the training and testing data from the features dataset\n",
    "X_train_scaled = X_scaler.transform(X_train)\n",
    "X_test_scaled = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Create and Evaluate a Deep Neural Network Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Create a deep neural network model with the following structure:\n",
    "\n",
    "    * 9 inputs\n",
    "    * First hidden layer with 18 neurons\n",
    "    * Second hidden layer with 8 neurons\n",
    "    * Output layer with a single output\n",
    "    * Hidden layers use the ReLU activation function, and output layer uses the sigmoid activation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the the number of inputs to the model - ######### Number of variables\n",
    "number_inputs = 9 \n",
    "\n",
    "# Define the number of hidden nodes for the first hidden layer ######## 18 neurons\n",
    "hidden_nodes_layer1 = 18 \n",
    "\n",
    "# Define the number of hidden nodes for the second hidden layer ####### 8 neurons\n",
    "hidden_nodes_layer2 = 8\n",
    "\n",
    "# Create the Sequential model instance\n",
    "nn = Sequential()\n",
    "\n",
    "# Add the first Dense layer specifying the number of inputs, the number of hidden nodes, and the activation function\n",
    "nn.add(Dense(units=hidden_nodes_layer1, activation=\"relu\", input_dim=number_inputs))\n",
    "\n",
    "# Add the second Dense layer specifying the number of hidden nodes and the activation function ###### dont need to add input_dim because it knows from before\n",
    "nn.add(Dense(units=hidden_nodes_layer2, activation=\"relu\")) \n",
    "\n",
    "# Add the output layer to the model specifying the number of output neurons and activation function\n",
    "nn.add(Dense(units=1, activation=\"sigmoid\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2. Display the model structure using the `summary` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Number of Params for first hidden layer should equal:\n",
    "\n",
    "#########         no. of neurons  x  number of inputs (X_variables)  +   no. of neurons\n",
    "\n",
    "#########  Simply , we get the number of neurons in that particular hidden layer, multiply it by the number of x variables (vectors of them) and then add back number of neurons due to the parameter for each (intercepts)\n",
    "18 * 9 + 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_9 (Dense)              (None, 18)                180       \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 8)                 152       \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1)                 9         \n",
      "=================================================================\n",
      "Total params: 341\n",
      "Trainable params: 341\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "nn.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: Compile the neural network model using the `binary_crossentropy` loss function, the `adam` optimizer, and `accuracy` as an additional metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the Sequential model\n",
    "nn.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"]) # loss function for binary issue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 4: Fit the model with the training data, using 100 epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/var/folders/nz/424vlqmj33v65fjkj1km03m80000gn/T/ipykernel_29488/3986347941.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Fit the model using 100 epochs and the training data\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Simply training the X_train on y_train\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[1;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 728\u001b[0;31m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[1;32m    729\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[1;32m    222\u001b[0m           \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_data\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m           \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 224\u001b[0;31m           distribution_strategy=strategy)\n\u001b[0m\u001b[1;32m    225\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    226\u001b[0m       \u001b[0mtotal_samples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_total_number_of_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_data_adapter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/training_v2.py\u001b[0m in \u001b[0;36m_process_training_inputs\u001b[0;34m(model, x, y, batch_size, epochs, sample_weights, class_weights, steps_per_epoch, validation_split, validation_data, validation_steps, shuffle, distribution_strategy, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    495\u001b[0m                      'at same time.')\n\u001b[1;32m    496\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 497\u001b[0;31m   \u001b[0madapter_cls\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdata_adapter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselect_data_adapter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    498\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    499\u001b[0m   \u001b[0;31m# Handle validation_split, we want to split the data and get the training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/anaconda3/envs/dev/lib/python3.7/site-packages/tensorflow_core/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mselect_data_adapter\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    651\u001b[0m         \u001b[0;34m\"Failed to find data adapter that can handle \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    652\u001b[0m         \"input: {}, {}\".format(\n\u001b[0;32m--> 653\u001b[0;31m             _type_name(x), _type_name(y)))\n\u001b[0m\u001b[1;32m    654\u001b[0m   \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0madapter_cls\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     raise RuntimeError(\n",
      "\u001b[0;31mValueError\u001b[0m: Failed to find data adapter that can handle input: <class 'numpy.ndarray'>, <class 'pandas.core.series.Series'>"
     ]
    }
   ],
   "source": [
    "# Fit the model using 100 epochs and the training data\n",
    "model = nn.fit(X_train_scaled, y_train, epochs=20) # Simply training the X_train on y_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 5: Evaluate the model using testing data and the `evaluate` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "782/782 - 0s - loss: 0.0060 - accuracy: 0.9988\n",
      "Loss: 0.006045293528586626, Accuracy: 0.9987999796867371\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model loss and accuracy metrics using the evaluate method and the test data\n",
    "model_loss, model_accuracy =  nn.evaluate(X_test_scaled, y_test, verbose = 2)\n",
    "\n",
    "# Display the evaluation results\n",
    "print(f\"Loss: {model_loss}, Accuracy: {model_accuracy}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Improving Model Accuracy:"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Increase neurons in existing hidden layers<br>2. Increase number of hidden layers<br>3. Test different activation functions (first to try, because easy)<br>4. Using more epochs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
